# Milestone 5 ðŸš€ - Deployment & Streamlit App/

## Evaluation & Results Communication

This directory contains all deliverables for Milestone 5 of the *Diabetes-Risk-XAI* project.  
The milestone focuses on:

- Evaluating the trained model
- Performing detailed validation analysis
- Conducting interpretability (XAI) checks
- Preparing communication materials for stakeholders
- Summarizing findings for both technical and non-technical audiences

---

## Included Files

### 1. `milestone5.md`  

Primary milestone documentation summarizing:

- Evaluation methodology  
- Performance metrics  
- Error analysis  
- Interpretability results  
- Communication strategy  

### 2. `evaluation_report.md`  

A detailed and expanded version of the evaluation results, including charts, tables, and deeper model diagnostics.

### 3. `communication_results.md`  

A communication-focused document presenting the milestoneâ€™s results in a clear, structured, and presentation-ready format.

### 4. `stakeholder_summary.md`  

A non-technical explanation of the project results and real-world relevance.

---

## Purpose of Milestone 5

This milestone verifies that the model is:

- reliable  
- explainable  
- ready for real-world use  
- supported by strong communication materials  

It prepares the project for final packaging and deployment in Milestone 6.

This directory contains the Streamlit deployment for the Diabetes Risk XAI
project.

## What is included

- `app/streamlit_app.py` â€” production-ready Streamlit app that:
  - Loads model artifacts from `/models/`
  - Displays prediction UI (enter patient features)
  - Shows predicted probability and color-coded severity
  - Renders SHAP force HTML files and LIME HTML files generated by the XAI
    notebook (`03_explainability.ipynb`)
  - Allows download of artifacts

- `milestone5.md` â€” narrative & deliverables for the milestone.

## How to run locally

1. Activate your project virtual environment with all dependencies installed:

   ```bash
   python -m venv .venv
   .venv\Scripts\activate    # Windows
   pip install -r requirements.txt

2. From the repo root run:

   ```bash
   streamlit run milestones/milestone5_deployment/app/streamlit_app.py

3. If we prefer to run from inside the milestone folder:

   ```bash
   cd milestones/milestone5_deployment
   streamlit run app/streamlit_app.py

## How to deploy to Streamlit Community Cloud

1. Push the repo to GitHub (we must be sure models/, results/ and milestones/\
   milestone5_deployment/app/streamlit_app.py are present).
2. Go to <https://share.streamlit.io> and connect to GitHub repo.
3. Select milestones/milestone5_deployment/app/streamlit_app.py as the
   entrypoint.
4. Provide required secrets/environment variables if the model is large or if
   the store model in a private location.

Streamlit Community Cloud is preferred for it is the fastest way to deploy
with minimal config.

## Notes & best practices

- The app reads artifact HTML files from the repo results/ folder. Regenerate
  them by running milestones/milestone3_xai/notebooks/03_explainability.ipynb
  when needed.
- We intentionally allow print() statements in notebooks for interactive
  debugging. Production code (this app) avoids noisy prints.

---

## Project Artifacts

Milestone 5 consolidates all public-facing outputs of the project. These
artifacts demonstrate the functionality, explainability, and reproducibility
of the diabetes-risk prediction system.

### ðŸ”¹ Deployed Streamlit Application

- An interactive web app that allows users to:
- Enter patient clinical features
- Generate real-time diabetes-risk predictions
- View SHAP-based explainability visualizations
- Access model decision interpretations
- App URL: [**Streamlit**](
  https://diabetes-risk-xai-cuxn9elwmgaukdbnbfmq65.streamlit.app/)

### ðŸ”¹ XAI Visualizations

These explainability assets help stakeholders understand how and why the model makes its predictions:

- SHAP Summary (Beeswarm) Plot â€“ global feature influence
- SHAP Summary (Bar) Plot â€“ ranked feature importance
- SHAP Force Plots â€“ individualized prediction explanations
- LIME Case Explanations â€“ local interpretability for selected records

Artifacts location:\
results/

### ðŸ”¹ Model Artifacts

All trained models used in this study, stored for reproducibility, auditing, and future development:

- xgb_final_model.joblib
- logreg_baseline.joblib
- xgb_tuned.joblib
- scaler.joblib

Artifacts location:\
models/

### ðŸ”¹ Evaluation Outputs

Performance summaries generated across multiple milestones:

- Baseline metrics
- Tuned model metrics
- Calibration curve
- XAI summary reports

Artifacts location:\
results/

### ðŸ”¹ Technical Notebooks

Reproducible Jupyter notebooks that document the analysis and modeling pipeline:

- EDA & Baseline Modeling: milestone2/notebooks/01+02_exploration.ipynb
- Explainability: milestone3/notebooks/03_explainability.ipynb
- Model Tuning: milestone4/notebooks/04_tuning.ipynb

### ðŸ”¹ Final Report & Supporting Documents

- Comprehensive final report (PDF)
- Executive one-page summary (PDF)
- Executive (Stakeholder) summary
- Presentation slides (pptx)
- Presentation (video)
- Presentation 2.5 minutes (audio)

Artifacts location:\
milestone6_final_report/

### ðŸ”¹ Source Code for Deployment

The full Streamlit application implementation:

```bash
milestone5_deployment/app/streamlit_app.py
```
